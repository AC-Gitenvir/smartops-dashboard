{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8323bdec-ca71-4ae0-8e33-ad20aa65221e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush\\AppData\\Local\\Temp\\ipykernel_7460\\2599934204.py:42: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import psutil\n",
    "import platform\n",
    "import gradio as gr\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.tools import Tool\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "# üîê Set your Gemini API key\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBN3i6tm57FeEWueX8qt7VdydhfDaY71Gg\"  # Replace this\n",
    "\n",
    "# üõ† Define system tools with single string input\n",
    "def get_cpu_info(input: str) -> str:\n",
    "    return f\"CPU Usage: {psutil.cpu_percent()}%\"\n",
    "\n",
    "def get_memory_info(input: str) -> str:\n",
    "    mem = psutil.virtual_memory()\n",
    "    return f\"Memory ‚Äî Total: {mem.total // (1024*2)} MB, Available: {mem.available // (1024*2)} MB\"\n",
    "\n",
    "def get_system_info(input: str) -> str:\n",
    "    sys = platform.uname()\n",
    "    return f\"System: {sys.system}, Node: {sys.node}, Processor: {sys.processor}, Version: {sys.version}\"\n",
    "\n",
    "# Optional: Add disk usage\n",
    "def get_disk_info(input: str) -> str:\n",
    "    disk = psutil.disk_usage('/')\n",
    "    return f\"Disk ‚Äî Total: {disk.total // (1024*3)} GB, Free: {disk.free // (1024*3)} GB\"\n",
    "\n",
    "# üîó Wrap into LangChain Tools\n",
    "tools = [\n",
    "    Tool(name=\"CPU Info\", func=get_cpu_info, description=\"Returns current CPU usage\"),\n",
    "    Tool(name=\"Memory Info\", func=get_memory_info, description=\"Returns memory stats\"),\n",
    "    Tool(name=\"System Info\", func=get_system_info, description=\"Returns system and OS info\"),\n",
    "    Tool(name=\"Disk Info\", func=get_disk_info, description=\"Returns disk space usage\")\n",
    "]\n",
    "\n",
    "# ü§ñ Load Gemini LLM\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.2)\n",
    "\n",
    "# ü§ù Create LangChain Agent\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# üß† Define Gradio interaction\n",
    "def chat_with_agent(user_input):\n",
    "    try:\n",
    "        response = agent.run(user_input)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error: {str(e)}\"\n",
    "\n",
    "# üåê Build Gradio Interface\n",
    "interface = gr.Interface(\n",
    "    fn=chat_with_agent,\n",
    "    inputs=gr.Textbox(lines=2, placeholder=\"Ask about your system... (e.g., What is my CPU usage?)\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"üß† AI System Info Agent\",\n",
    "    description=\"Ask questions about your system (CPU, memory, disk, OS) using an AI agent powered by Gemini + LangChain.\"\n",
    ")\n",
    "\n",
    "# üöÄ Launch it\n",
    "interface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc6fc9b-75cb-4fb3-920f-a74cda64720b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
