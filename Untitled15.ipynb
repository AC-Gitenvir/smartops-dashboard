{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8323bdec-ca71-4ae0-8e33-ad20aa65221e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush\\AppData\\Local\\Temp\\ipykernel_25064\\2599934204.py:42: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\threading.py\", line 1032, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\site-packages\\uvicorn\\server.py\", line 67, in run\n",
      "    return asyncio.run(self.serve(sockets=sockets))\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\asyncio\\runners.py\", line 194, in run\n",
      "    return runner.run(main)\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\asyncio\\runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\asyncio\\base_events.py\", line 674, in run_until_complete\n",
      "    self.run_forever()\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 626, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 321, in call_process_api\n",
      "    with utils.MatplotlibBackendMananger():\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 1099, in __enter__\n",
      "    import matplotlib\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\site-packages\\matplotlib\\__init__.py\", line 159, in <module>\n",
      "    from . import _api, _version, cbook, _docstring, rcsetup\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\site-packages\\matplotlib\\rcsetup.py\", line 28, in <module>\n",
      "    from matplotlib.colors import Colormap, is_color_like\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\site-packages\\matplotlib\\colors.py\", line 57, in <module>\n",
      "    from matplotlib import _api, _cm, cbook, scale\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\site-packages\\matplotlib\\scale.py\", line 22, in <module>\n",
      "    from matplotlib.ticker import (\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\site-packages\\matplotlib\\ticker.py\", line 144, in <module>\n",
      "    from matplotlib import transforms as mtransforms\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 49, in <module>\n",
      "    from matplotlib._path import (\n",
      "C:\\Users\\Ayush\\AppData\\Local\\Temp\\ipykernel_25064\\2599934204.py:52: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = agent.run(user_input)\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\threading.py\", line 1032, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\site-packages\\uvicorn\\server.py\", line 67, in run\n",
      "    return asyncio.run(self.serve(sockets=sockets))\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\asyncio\\runners.py\", line 194, in run\n",
      "    return runner.run(main)\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\asyncio\\runners.py\", line 118, in run\n",
      "    return self._loop.run_until_complete(task)\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\asyncio\\base_events.py\", line 674, in run_until_complete\n",
      "    self.run_forever()\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 626, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 321, in call_process_api\n",
      "    with utils.MatplotlibBackendMananger():\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 1108, in __exit__\n",
      "    import matplotlib\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\site-packages\\matplotlib\\__init__.py\", line 159, in <module>\n",
      "    from . import _api, _version, cbook, _docstring, rcsetup\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\site-packages\\matplotlib\\rcsetup.py\", line 28, in <module>\n",
      "    from matplotlib.colors import Colormap, is_color_like\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\site-packages\\matplotlib\\colors.py\", line 57, in <module>\n",
      "    from matplotlib import _api, _cm, cbook, scale\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\site-packages\\matplotlib\\scale.py\", line 22, in <module>\n",
      "    from matplotlib.ticker import (\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\site-packages\\matplotlib\\ticker.py\", line 144, in <module>\n",
      "    from matplotlib import transforms as mtransforms\n",
      "  File \"C:\\Users\\Ayush\\anaconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 49, in <module>\n",
      "    from matplotlib._path import (\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import psutil\n",
    "import platform\n",
    "import gradio as gr\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.tools import Tool\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "# üîê Set your Gemini API key\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBN3i6tm57FeEWueX8qt7VdydhfDaY71Gg\"  # Replace this\n",
    "\n",
    "# üõ† Define system tools with single string input\n",
    "def get_cpu_info(input: str) -> str:\n",
    "    return f\"CPU Usage: {psutil.cpu_percent()}%\"\n",
    "\n",
    "def get_memory_info(input: str) -> str:\n",
    "    mem = psutil.virtual_memory()\n",
    "    return f\"Memory ‚Äî Total: {mem.total // (1024*2)} MB, Available: {mem.available // (1024*2)} MB\"\n",
    "\n",
    "def get_system_info(input: str) -> str:\n",
    "    sys = platform.uname()\n",
    "    return f\"System: {sys.system}, Node: {sys.node}, Processor: {sys.processor}, Version: {sys.version}\"\n",
    "\n",
    "# Optional: Add disk usage\n",
    "def get_disk_info(input: str) -> str:\n",
    "    disk = psutil.disk_usage('/')\n",
    "    return f\"Disk ‚Äî Total: {disk.total // (1024*3)} GB, Free: {disk.free // (1024*3)} GB\"\n",
    "\n",
    "# üîó Wrap into LangChain Tools\n",
    "tools = [\n",
    "    Tool(name=\"CPU Info\", func=get_cpu_info, description=\"Returns current CPU usage\"),\n",
    "    Tool(name=\"Memory Info\", func=get_memory_info, description=\"Returns memory stats\"),\n",
    "    Tool(name=\"System Info\", func=get_system_info, description=\"Returns system and OS info\"),\n",
    "    Tool(name=\"Disk Info\", func=get_disk_info, description=\"Returns disk space usage\")\n",
    "]\n",
    "\n",
    "# ü§ñ Load Gemini LLM\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.2)\n",
    "\n",
    "# ü§ù Create LangChain Agent\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# üß† Define Gradio interaction\n",
    "def chat_with_agent(user_input):\n",
    "    try:\n",
    "        response = agent.run(user_input)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error: {str(e)}\"\n",
    "\n",
    "# üåê Build Gradio Interface\n",
    "interface = gr.Interface(\n",
    "    fn=chat_with_agent,\n",
    "    inputs=gr.Textbox(lines=2, placeholder=\"Ask about your system... (e.g., What is my CPU usage?)\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"üß† AI System Info Agent\",\n",
    "    description=\"Ask questions about your system (CPU, memory, disk, OS) using an AI agent powered by Gemini + LangChain.\"\n",
    ")\n",
    "\n",
    "# üöÄ Launch it\n",
    "interface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc6fc9b-75cb-4fb3-920f-a74cda64720b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
